library(RColorBrewer)
library(ggplot2)
library(flexclust)
library(caret)
library(cluster)
library(dplyr)
# Data import
airline <- read.csv("AirlinesCluster.csv")
setwd("~/Google Drive/Colab Notebooks/R/5.3.segmentation")
# Data import
airline <- read.csv("AirlinesCluster.csv")
# Data import
airline <- read.csv("data/AirlinesCluster.csv")
# Data display
head(airline, 16)
tail(airline, 5)
colMeans(airline)
apply(airline, 2, sd)
# Normalization
pp <- preProcess(airline, method=c("center", "scale"))
airline.scaled <- predict(pp, airline)
# Data display
head(airline, 16)
tail(airline, 5)
colMeans(airline)
apply(airline, 2, sd)
??apply
?apply
# Data display
head(airline, 16)
apply(airline, 2, sd)
# Normalization
pp <- preProcess(airline, method=c("center", "scale"))
airline.scaled <- predict(pp, airline)
# Display of nromalized data
head(round(airline.scaled, 2), 16)
tail(round(airline.scaled, 2), 5)
set.seed(144)
# Running the k means algorithm
mod <- kmeans(airline.scaled, iter.max=100, 8)
# Display of nromalized data
head(round(airline.scaled, 2), 16)
tail(round(airline.scaled, 2), 5)
set.seed(144)
# Running the k means algorithm
mod <- kmeans(airline.scaled, iter.max=100, 8)
cluster.assignment.kmeans <- mod$cluster
?kmeans
# Running the k means algorithm
mod <- kmeans(airline.scaled, iter.max=100, 8)
cluster.assignment.kmeans <- mod$cluster
# Summary of results
t(round(mod$centers, 2))
round(t(mod$centers) * pp$std + pp$mean)
table(mod$cluster)
# Running the k means algorithm for each k
dat <- data.frame(k = 1:100)
dat$SS <- sapply(dat$k, function(k) {
set.seed(144)
kmeans(airline.scaled, iter.max=100, k)$tot.withinss
})
# Plotting the results
print(ggplot(dat, aes(x=k, y=SS)) +
geom_line(lwd=2) +
theme_bw() +
xlab("Number of Clusters (k)") +
ylab("Within-Cluster Sum of Squares") +
ylim(0, 25000) +
theme(axis.title=element_text(size=18), axis.text=element_text(size=18)))
d <- dist(airline.scaled)
mod.hclust <- hclust(d, method="ward.D2")
dissimilarity.all <- c(75,50,32,25,20,15)
plot(mod.hclust, labels=F, xlab=NA, ylab="Dissimilarity", sub=NA, main=NA)
plot(mod.hclust, labels=F, xlab=NA, ylab="Dissimilarity", sub=NA, main=NA)
# Varying the number of clusters
dat.hc.airline <- data.frame(nclust = seq_along(mod.hclust$height),
dissimilarity = rev(mod.hclust$height))
# Plotting the results
print(ggplot(dat.hc.airline, aes(x=nclust, y=dissimilarity)) +
geom_line(lwd=2) +
theme_bw() +
xlab("Number of Clusters") +
ylab("Dissimilarity") +
xlim(0, 100) +
theme(axis.title=element_text(size=18), axis.text=element_text(size=18)))
# Assignment of data points to clusters
assignments <- cutree(mod.hclust, 7)
# Display clusters
round(sapply(split(airline.scaled, assignments), colMeans), 2)
table(assignments)
# Data import
data(auto)
# Data wrangling
auto.cutdown <- auto[,c("ch_driving_properties", "ch_interior", "ch_technology", "ch_comfort", "ch_reliability",
"ch_handling", "ch_power", "ch_consumption", "ch_sporty", "ch_safety")]
for (k in names(auto.cutdown)) {
auto.cutdown[,k] <- as.numeric(auto.cutdown[,k])
}
names(auto.cutdown) <- substr(names(auto.cutdown), 4, nchar(names(auto.cutdown)))
# Display
head(auto.cutdown, 16)
tail(auto.cutdown, 5)
# Running the hierarchical clustering algorithm
d <- dist(auto.cutdown)
mod.hclust <- hclust(d, method="ward.D2")
plot(mod.hclust, labels=F, xlab=NA, ylab="Dissimilarity", sub=NA, main=NA)
plot(mod.hclust, labels=F, xlab=NA, ylab="Dissimilarity", sub=NA, main=NA)
# Computing the scree plot
dat.hc.auto <- data.frame(nclust = seq_along(mod.hclust$height),
dissimilarity = rev(mod.hclust$height))
print(ggplot(dat.hc.auto, aes(x=nclust, y=dissimilarity)) +
geom_line(lwd=2) +
theme_bw() +
xlab("Number of Clusters") +
ylab("Dissimilarity") +
xlim(0, 100) +
theme(axis.title=element_text(size=18), axis.text=element_text(size=18)))
# Assignment of data points to clusters
assignments <- cutree(mod.hclust, 7)
# Display clusters
round(sapply(split(auto.cutdown, assignments), colMeans), 2)
table(assignments)
library(RColorBrewer)
library(ggplot2)
library(flexclust)
library(caret)
library(cluster)
library(dplyr)
# Data import
airline <- read.csv("data/AirlinesCluster.csv")
# Data display
head(airline, 16)
tail(airline, 5)
colMeans(airline)
apply(airline, 2, sd)
# Normalization
pp <- preProcess(airline, method=c("center", "scale"))
airline.scaled <- predict(pp, airline)
# Display of nromalized data
head(round(airline.scaled, 2), 16)
tail(round(airline.scaled, 2), 5)
set.seed(144)
# Running the k means algorithm
mod <- kmeans(airline.scaled, iter.max=100, 8)
cluster.assignment.kmeans <- mod$cluster
# Summary of results
t(round(mod$centers, 2))
round(t(mod$centers) * pp$std + pp$mean)
table(mod$cluster)
# Running the k means algorithm for each k
dat <- data.frame(k = 1:100)
dat$SS <- sapply(dat$k, function(k) {
set.seed(144)
kmeans(airline.scaled, iter.max=100, k)$tot.withinss
})
# Plotting the results
print(ggplot(dat, aes(x=k, y=SS)) +
geom_line(lwd=2) +
theme_bw() +
xlab("Number of Clusters (k)") +
ylab("Within-Cluster Sum of Squares") +
ylim(0, 25000) +
theme(axis.title=element_text(size=18), axis.text=element_text(size=18)))
d <- dist(airline.scaled)
mod.hclust <- hclust(d, method="ward.D2")
dissimilarity.all <- c(75,50,32,25,20,15)
plot(mod.hclust, labels=F, xlab=NA, ylab="Dissimilarity", sub=NA, main=NA)
plot(mod.hclust, labels=F, xlab=NA, ylab="Dissimilarity", sub=NA, main=NA)
# Varying the number of clusters
dat.hc.airline <- data.frame(nclust = seq_along(mod.hclust$height),
dissimilarity = rev(mod.hclust$height))
# Plotting the results
print(ggplot(dat.hc.airline, aes(x=nclust, y=dissimilarity)) +
geom_line(lwd=2) +
theme_bw() +
xlab("Number of Clusters") +
ylab("Dissimilarity") +
xlim(0, 100) +
theme(axis.title=element_text(size=18), axis.text=element_text(size=18)))
# Assignment of data points to clusters
assignments <- cutree(mod.hclust, 7)
# Display clusters
round(sapply(split(airline.scaled, assignments), colMeans), 2)
table(assignments)
library(caret)
library(caret)
# after setting the current directory, we load the airline data
airline <- read.csv("data/airline.csv")
# after setting the current directory, we load the airline data
airline <- read.csv("/data/AirlinesCluster.csv")
# after setting the current directory, we load the airline data
airline <- read.csv("data/AirlinesCluster.csv")
str(airline)
#step 1: create the pre-processor using preProcess
?preProcess
pp <- preProcess(airline, method=c("center", "scale"))   # normalization for each col: (X_i-mean)/std
class(pp)
pp
pp$mean
#step 2: apply it to our dataset
airline.scaled <- predict(pp, airline)
# Sanity check
colMeans(airline)
colMeans(airline.scaled)# mean is (approximately) 0 for all columns
apply(airline.scaled,2,sd)# standard deviation is 1 for all columns (apply() applies function given as third argument to matrix given as first argument. 2 means apply sd() to cols. 1 would apply it row-wise, col(1,2) both to row and column.)
head(airline.scaled)
# k-means has a random start (where the centroids are initially randomly located)
# we need to set the seed to have the same result
set.seed(144)
# The kmeans function creates the clusters
# we can set an upper bound to the number of iterations
# of the algorithm
# here we set k=8
km <- kmeans(airline.scaled, centers = 8, iter.max=100) # centers randomly selected from rows of airline.scaled
class(km) # class: kmeans
names(km) # Take a look at what's inside this object.
# Let's explore the results!
# cluster centroids. Store this result
km.centroids <- km$centers
km.centroids
# cluster for each point. Store this result.
km.clusters <- km$cluster
km.clusters
# the sum of the squared distances of each observation from its cluster centroid.
# we use it the measure cluster dissimilarity
km$tot.withinss  # cluster dissimilarity
# the number of observations in each cluster -- table(km$cluster) also works. Store this resul
km.size <- km$size
km.size
# Scree plot for k-means
# For k means, we literally try many value of k and look at their dissimilarity.
# here we test all k from 1 to 100
k.data <- data.frame(k = 1:100)
k.data$SS <- sapply(k.data$k, function(k) {
kmeans(airline.scaled, iter.max=100, k)$tot.withinss
})
# Plot the scree plot.
plot(k.data$k, k.data$SS, type="l")
### PART 3 : Hierarchical Clustering
# Compute all-pair euclidian distances between our observations
d <- dist(airline.scaled)    # method = "euclidean"
class(d)
# Creates the Hierarchical clustering
hclust.mod <- hclust(d, method="ward.D2")
# Now, we can plot the hierarchy structure (dendrogram)
# labels=F (false) because we do not want to print text
# for each of the 3999 observations
plot(hclust.mod, labels=F, ylab="Dissimilarity", xlab = "", sub = "")
# To choose a good value for k, we need to create the scree plot: dissimilarity for each k
# the next line puts this data in the right form to be plotted
hc.dissim <- data.frame(k = seq_along(hclust.mod$height),   # index: 1,2,...,length(hclust.mod$height)
dissimilarity = rev(hclust.mod$height)) # reverse elements
head(hc.dissim)
# Scree plot
plot(hc.dissim$k, hc.dissim$dissimilarity, type="l")
# Let's zoom on the smallest k values:
plot(hc.dissim$k, hc.dissim$dissimilarity, type="l", xlim=c(0,40))
axis(side = 1, at = 1:10)
# Improvement in dissimilarity for increasing number of clusters
hc.dissim.dif = head(hc.dissim,-1)-tail(hc.dissim,-1)
head(hc.dissim.dif,10)
# now that we have k (we chose k=7 in the lecture), we can construct the clusters
h.clusters <- cutree(hclust.mod, 7)
h.clusters
# The *centroid* for a cluster is the mean value of all points in the cluster:
aggregate(airline.scaled, by=list(h.clusters), mean) # Compute centroids
# Look at the *size* of each cluster
table(h.clusters)
# Compare the clusters from kmeans and Hierarchical. Do some clusters "match up"? (Yes, because there are alot of zeros.)
table(h.clusters, km.clusters)
# after setting the current directory, loading the airline data
airline <- read.csv("data/AirlinesCluster.csv")
library(caret)
# after setting the current directory, loading the airline data
airline <- read.csv("data/AirlinesCluster.csv")
# after setting the current directory, loading the airline data
airline <- read.csv("data/airline.csv")
str(airline)
head(airline)
tail(airline)
head(airline)
tail(airline)
airline
# after setting the current directory, loading the airline data
airline <- read.csv("data/airline.csv")
str(airline)
airline
#step 1: create the pre-processor using preProcess
?preProcess
# after setting the current directory, loading the airline data
airline <- read.csv("data/airline.csv")
str(airline)
airline
#step 1: create the pre-processor using preProcess
pp <- preProcess(airline, method=c("center", "scale"))   # normalization for each col: (X_i-mean)/std
class(pp)
pp
pp$mean
#step 2: apply it to our dataset
airline.scaled <- predict(pp, airline)
# Sanity check
colMeans(airline)
colMeans(airline.scaled)# mean is (approximately) 0 for all columns
apply(airline.scaled,2,sd)# standard deviation is 1 for all columns (apply() applies function given as third argument to matrix given as first argument. 2 means apply sd() to cols. 1 would apply it row-wise, col(1,2) both to row and column.)
head(airline.scaled)
